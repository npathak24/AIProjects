{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1adbb432",
   "metadata": {},
   "source": [
    "# AIDI-2000  Exercise-2 (CNN model on MNIST Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a53afe",
   "metadata": {},
   "source": [
    "Student Id - 100899717\n",
    "Student Name - Naman Pathak"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed417ef4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6e66a2a",
   "metadata": {},
   "source": [
    "# Stage-1 Data Loading, Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5d313",
   "metadata": {},
   "source": [
    "First, we need to import the required libraries and load the MNIST dataset. We will be using the TensorFlow library for building and training our CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448c0c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGZCAYAAABmNy2oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWS0lEQVR4nO3ceYxV5fnA8Wc6DJsISLEiVgGxgmyhacSlrkxp0baJjFtIrAtKTatRk6pNbVKkCWprbSqttNhU1IrgEhEXqCtoUpdibRvcg1urglhBBco28v7+8McTRkQ4F0GWzyeZRM+c5z3nMnfmO+dyOXWllBIAEBFf+LxPAIBthygAkEQBgCQKACRRACCJAgBJFABIogBAEgUA0k4Theuvvz7q6uriqaee+kzWq6uri3PPPfczWWvdNS+99NKaZi+99NKoq6uLurq66NChw3qff/rpp+Mb3/hGdOjQITp37hxNTU3xyiuvbNb5vvLKK9HU1BSdO3eODh06xLBhw+Lpp5/erDUXLlwYp59+enTt2jXat28fhxxySDz00EObtebSpUvjggsuiO7du0fbtm1j8ODBMXXq1M1ac/Xq1TF27Njo2bNntGnTJvr27Ru//e1vN2vN3/zmN9HU1BS9evWKurq6OOqoozZrvbWmTp0agwcPjrZt20b37t3jggsuiKVLl27Wmg8++GAccsgh0b59++jatWucfvrpsXDhws1ac1t7jh533HH5PTVgwIDNOo/tyU4ThZ3F448/HrNmzWqx7YUXXoijjjoqVq1aFbfeemtcd9118dJLL8Xhhx8e77zzTk3Heeedd+Lwww+Pl156Ka677rq49dZbY8WKFXHUUUfFiy++WNOaK1eujMbGxnjooYfi6quvjunTp8cee+wRw4cPj0ceeaSmNSMimpqa4oYbbogxY8bEzJkz48ADD4yRI0fGzTffXPOaP/zhD+Pyyy+Pc845J+67774YMWJEnH/++XHZZZfVvOYf/vCHeP3112Po0KGx++6717zOuiZPnhwjR46MAw88MGbOnBljxoyJ66+/Ppqammpe85FHHoljjjkm9thjj5g+fXpcffXV8eCDD0ZjY2OsXLmypjW3xefoL3/5y3j88cfjq1/9ak3H326VncSkSZNKRJQ5c+Z8JutFRDnnnHM+k7XWXXPMmDE1zY4ZM6Zs6Mt54oknlq5du5b3338/t7322muloaGhXHzxxTUd76KLLioNDQ3ltddey23vv/9+6dq1aznppJNqWvOaa64pEVEee+yx3LZ69erSr1+/MmTIkJrWvPfee0tElJtvvrnF9mHDhpXu3buX5ubmyms+88wzpa6urlx22WUtto8ePbq0a9euvPvuuzWd64cffpj/3b9//3LkkUfWtM5azc3NZc899yzf/OY3W2yfPHlyiYgyY8aMmtY98MADS79+/crq1atz21//+tcSEWXChAk1rbktP0ePPPLI0r9//5rOYXvkSmEdK1asiB/96EcxePDg6NSpU3Tp0iUOOeSQmD59+gZnJk6cGPvvv3+0adMm+vXr94kvSyxYsCDOPvvs+PKXvxytW7eOXr16xdixY6O5uXlLPpyIiGhubo577rknjj/++OjYsWNu79GjRxx99NExbdq0mtadNm1aDB06NHr06JHbOnbsGE1NTXH33XfX9NimTZsWffr0iUMOOSS3tWrVKk455ZT429/+Fm+++WZNa3bo0CFOPPHEFtvPOOOMeOutt+LJJ5+svOadd94ZpZQ444wz1ltz+fLl8Ze//KXymhERX/jCZ/vt+MQTT8T8+fPXO88TTzwxOnToUNPX/s0334w5c+bE9773vWjVqlVuP/TQQ2P//fevac3t6Tm6MxCFdaxcuTIWLVoUF154Ydx5550xZcqUOOyww6KpqSluvPHG9fa/6667Yvz48fHzn/88br/99ujRo0eMHDkybr/99txnwYIFMWTIkLjvvvviZz/7WcycOTPOPPPMuPzyy2P06NEbPaeePXtGz549a35ML7/8cixfvjwGDRq03ucGDRoU8+bNixUrVlRac/ny5fHyyy9vcM3ly5fX9FrwM888s8E1IyKeffbZmtY84IADWvwAW3fNZ555pqY1d9999+jWrdtntuaWsPY8Pv5n2tDQEH379q35sX/Smmu31bLm9vQc3Rm02vguO49OnTrFpEmT8v8//PDDaGxsjMWLF8dvfvObOPXUU1vs/9///jfmzJkTe+yxR0REHHvssTFgwID4yU9+EieccEJEfPQXwIsXL45nn3029tlnn4iIaGxsjHbt2sWFF14YF110UfTr12+D5/TxH2ZVvfvuuxER0aVLl/U+16VLlyilxOLFi2PPPffc5DUXL14cpZQNrrnucaue65ZYc9999/3M1/yk89xll12idevWNa25JWzsa//aa6995mvW+uf5aWtuS8/RnYErhY+57bbb4utf/3p06NAhWrVqFQ0NDfGnP/0pnn/++fX2bWxszCBERNTX18fJJ58c8+bNizfeeCMiIu655544+uijo3v37tHc3JwfxxxzTETERv8Cdd68eTFv3rzNflx1dXU1fc6aW2/NLWVD57M557k119ycdbenr9O2QhTWcccdd8RJJ50Ue+21V9x0003x+OOPx5w5c2LUqFGfePn68ZcP1t229reQt99+O+6+++5oaGho8dG/f/+I+OhqY0v64he/2OJ81rVo0aKoq6uLzp07V1pzt912i7q6ug2uGfHJv/Vtyrluz2suW7YsVq1aVdOaW8LGvva1Pvatvea29BzdGXj5aB033XRT9OrVK2655ZYWv0Vs6G12CxYs2OC2tU/0rl27xqBBg2LcuHGfuEb37t0397Q/Ve/evaNdu3Yxd+7c9T43d+7c2G+//aJt27aV1mzXrl3st99+G1yzXbt2n/iSzcYMHDhwg2tGRE3vFR84cGBMmTIlmpubW7wUt7lrTp06NRYsWNDiF4PNWXNLGDhwYER8dF7rvkTZ3NwcL7zwQowcObLymmsf29y5c+PYY49t8bm5c+fW9Ni3p+foTuFzfe/TVrQpb0ltamoqffr0abFt/vz5pUOHDuu93TMiSrt27cqCBQtyW3Nzc+nbt2/p3bt3bjvrrLNK9+7dy6JFizZ6jrGF3pJ60kknlS996Uvlgw8+yG2vv/56ad26dfnxj39c0/Euvvji0rp16/Lvf/87t33wwQdl9913LyeffHJNa06YMKFERHniiSdy2+rVq0v//v3LQQcdVNOaM2bMKBFRpk6d2mL78OHDN/stqVdccUWL7WefffZmvSV1XZ/lW1KHDx/eYvuUKVNKRJSZM2fWtO6QIUPKgAEDWvzZPf744yUiyu9///ua1tyWn6M721tSd7oo/OIXvyi33Xbbeh/Lli0r1113XYmI8oMf/KA89NBD5frrry+9e/cuX/nKVz4xCnvvvXfp169fmTJlSrnrrrvK8OHD1/sB9NZbb5UePXqUvn37lgkTJpSHHnqo3HvvveWaa64p3/72t8t//vOfFmt+PAq9e/duEZkN+bQoPP/886VDhw7liCOOKDNmzCh33HFHGTBgQOnevXtZuHBhi33r6+vL0KFDN3q8hQsXlj333LMMHDiwTJs2rcyYMaMcccQRZddddy3PP/98TY9hxYoVpX///mXvvfcukydPLg888EAZMWJEadWqVZk9e3aLfYcOHVrq6+s3umYpH/2bhN12261ce+215eGHHy6jR48uEVFuuummFvuNGjWq1NfXt3hf+4acddZZpU2bNuXKK68ss2fPLpdcckmpq6sr48aNa7Hf2LFjS319/Xrn/0nmzJmTz8e1z621/7/uOd1www2lvr6+3HDDDRtd889//nOJiPL973+/zJo1q1x77bWlc+fOZdiwYS32mz17dqmvry9jx47d6JqzZs0qrVq1KiNGjCgPPPBAmTx5ctl7773LgAEDyooVK3K/1157rdTX15dRo0ZtdM1t+TkqCjuotVHY0Merr75aSinliiuuKD179ixt2rQpBxxwQPnjH//4iT9w4///8dqECRNK7969S0NDQ+nbt2+ZPHnyesd+5513ynnnnVd69epVGhoaSpcuXcrXvva18tOf/rQsXbq0xZofj0KPHj1Kjx49Nvr4Pi0KpZTy1FNPlcbGxtK+ffvSsWPHctxxx5V58+att19EbPJvqPPmzSvHHXdc6dixY2nfvn1pbGwsf//739fbb1MfQymlLFiwoJx66qmlS5cupW3btuXggw8uDzzwwHr7HXnkkZ/6eNe1ZMmSct5555Vu3bqV1q1bl0GDBpUpU6ast99pp53W4rnwaVatWlXGjBlT9tlnn9K6deuy//77l/Hjx6+339qvy6xZsza65trjf9LHpEmTcr+1z+V1t32am2++uQwaNKi0bt26dOvWrZx33nllyZIlLfaZNWtWpSvV+++/vxx88MGlbdu2pUuXLuXUU08tb7/9dot9Xn311RIR5bTTTtukNbfV5+jOFoW6UkrZQq9MsRVdeumlMXbs2Fi9enXU1dVFfX39531KsF1bs2ZNrFmzJhobG+Pdd9/dZv79yZbm3Uc7mIaGhujUqdPnfRqw3WtqaoqGhoZ49NFHP+9T2apcKewg3nrrrXjrrbci4qN/L7HT3cQLPmMvv/xyLF68OCI+ejfT2reR7+hEAYDk5SMAkigAkEQBgLTJt7lw8yiA7dum/BWyKwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUqvP+wRgY+rr6yvPdOrUaQucyWfj3HPPrWmuffv2lWf69OlTeeacc86pPPOrX/2q8szIkSMrz0RErFixovLMFVdcUXlm7NixlWd2BK4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQ3BBvB7PPPvtUnmndunXlmUMPPbTyzGGHHVZ5JiKic+fOlWeOP/74mo61o3njjTcqz4wfP77yzIgRIyrPLFmypPJMRMS//vWvyjOPPPJITcfaGblSACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAqiullE3asa5uS58L6xg8eHBNcw8//HDlmU6dOtV0LLauNWvWVJ4ZNWpU5ZmlS5dWnqnF/Pnza5pbvHhx5ZkXX3yxpmPtaDblx70rBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAILlL6jaqS5cuNc09+eSTlWf23Xffmo61o6nlz+69996rPHP00UdXnomIWLVqVeUZd8BlXe6SCkAlogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkFp93ifAJ1u0aFFNcxdddFHlme985zuVZ/7xj39Unhk/fnzlmVr985//rDwzbNiwyjPLli2rPNO/f//KMxER559/fk1zUIUrBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApLpSStmkHevqtvS58Dnp2LFj5ZklS5ZUnpk4cWLlmYiIM888s/LMKaecUnlmypQplWdge7IpP+5dKQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAILX6vE+Az98HH3ywVY7z/vvvb5XjRESMHj268swtt9xSeWbNmjWVZ2Bb5koBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIdaWUskk71tVt6XNhB7fLLrvUNHf33XdXnjnyyCMrzxxzzDGVZ+6///7KM/B52ZQf964UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQ3BCPbV7v3r0rzzz99NOVZ957773KM7Nmzao889RTT1WeiYi45pprKs9s4rc3Owk3xAOgElEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEhuiMcOacSIEZVnJk2aVHlm1113rTxTq0suuaTyzI033lh5Zv78+ZVn2D64IR4AlYgCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEByQzz4fwMGDKg88+tf/7ryTGNjY+WZWk2cOLHyzLhx4yrPvPnmm5Vn2PrcEA+ASkQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACC5IR5shs6dO1ee+e53v1vTsSZNmlR5ppbv24cffrjyzLBhwyrPsPW5IR4AlYgCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSu6TCdmLlypWVZ1q1alV5prm5ufLMt771rcozs2fPrjzD5nGXVAAqEQUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgFT9blmwgxo0aFDlmRNOOKHyzIEHHlh5JqK2m9vV4rnnnqs88+ijj26BM+Hz4EoBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJDfHY5vXp06fyzLnnnlt5pqmpqfJMt27dKs9sTR9++GHlmfnz51eeWbNmTeUZtk2uFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkNwQj5rUciO4kSNH1nSsWm5u17Nnz5qOtS176qmnKs+MGzeu8sxdd91VeYYdhysFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkN8Tbweyxxx6VZ/r161d55ne/+13lmb59+1ae2dY9+eSTlWeuvPLKmo41ffr0yjNr1qyp6VjsvFwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAyV1St4IuXbpUnpk4cWJNxxo8eHDlmX333bemY23LHnvsscozV111VeWZ++67r/LM8uXLK8/A1uJKAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAaae+Id5BBx1Ueeaiiy6qPDNkyJDKM3vttVflmW3d//73v5rmxo8fX3nmsssuqzyzbNmyyjOwo3GlAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAtFPfEG/EiBFbZWZreu655yrP3HPPPZVnmpubK89cddVVlWciIt57772a5oDqXCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACDVlVLKJu1YV7elzwWALWhTfty7UgAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDUalN3LKVsyfMAYBvgSgGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA9H9X84L8sq5KIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Select a random sample from the training dataset\n",
    "sample_index = 0  # Change this value to visualize different samples\n",
    "sample_image = x_train[sample_index]\n",
    "sample_label = y_train[sample_index]\n",
    "\n",
    "# Reshape the image to 2D\n",
    "sample_image = sample_image.reshape(28, 28)\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.title(f\"Label: {sample_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179bb63e",
   "metadata": {},
   "source": [
    "In this code, we import the necessary TensorFlow modules and load the MNIST dataset using mnist.load_data(). The dataset is divided into training and testing sets, consisting of images and corresponding labels.\n",
    "\n",
    "Next, we preprocess the data by reshaping the images to have a single channel and normalizing the pixel values between 0 and 1.\n",
    "\n",
    "Next, we select a random sample from the training dataset by setting the value of sample_index. The corresponding image and label are extracted from the x_train and y_train arrays.\n",
    "\n",
    "The image is reshaped from a 3D array to a 2D array using reshape(28, 28) to match the original dimensions of the MNIST images.\n",
    "\n",
    "Finally, we use plt.imshow() to display the image with a grayscale colormap (cmap='gray'). We set the title of the plot to show the corresponding label, and plt.axis('off') is used to hide the axes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a9285",
   "metadata": {},
   "source": [
    "# Stage-2 Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9499bb6",
   "metadata": {},
   "source": [
    "Now, we'll define the architecture of our CNN model. This will include convolutional layers, pooling layers, and fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002344e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                102464    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,930\n",
      "Trainable params: 121,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffc2e7c",
   "metadata": {},
   "source": [
    "Here, we use the Sequential class from Keras to create a sequential model. We add layers to the model using the add() method.\n",
    "\n",
    "In this example, we have two convolutional layers with ReLU activation functions, followed by max pooling layers to downsample the feature maps. Then, we flatten the feature maps and add two fully connected layers. The final layer has 10 units with a softmax activation function, representing the probabilities for each digit class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef48db8",
   "metadata": {},
   "source": [
    "# Stage-3 Model Compilation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20384677",
   "metadata": {},
   "source": [
    "Next, we'll compile and train our model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca89083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.2369 - accuracy: 0.9294 - val_loss: 0.0654 - val_accuracy: 0.9797\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.0618 - accuracy: 0.9809 - val_loss: 0.0515 - val_accuracy: 0.9835\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.0430 - val_accuracy: 0.9857\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 0.0406 - val_accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.0378 - val_accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 48s 103ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.0336 - val_accuracy: 0.9895\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.0353 - val_accuracy: 0.9891\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0342 - val_accuracy: 0.9877\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0423 - val_accuracy: 0.9875\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0334 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c34b89b040>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd7e0e",
   "metadata": {},
   "source": [
    "In this code, we use the compile() method to configure the model for training. We specify the optimizer (Adam), loss function (categorical cross-entropy), and metrics (accuracy) to be used during training.\n",
    "\n",
    "We then use the fit() method to train the model on the training data. We set the batch size to 128 and train for 10 epochs. The validation data is provided to evaluate the model's performance after each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff333b9b",
   "metadata": {},
   "source": [
    "# Stage-4 Model Evaluation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ac332",
   "metadata": {},
   "source": [
    "After training, we can evaluate the performance of our model using the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f6f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0334 - accuracy: 0.9899\n",
      "Test loss: 0.0334\n",
      "Test accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849d6fc",
   "metadata": {},
   "source": [
    "In this code, we use the evaluate() method to calculate the loss and accuracy of the trained model on the testing data. The results are then printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a570b",
   "metadata": {},
   "source": [
    "# Stage-5 Performance Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fe8c4",
   "metadata": {},
   "source": [
    "To further analyze the performance of our model, we can calculate additional metrics such as precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd7e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.99      0.99      1032\n",
      "           3       1.00      0.98      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      1.00      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       1.00      0.98      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "y_true = tf.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be896786",
   "metadata": {},
   "source": [
    "Here, we use the classification_report() function from scikit-learn to calculate precision, recall, F1-score, and support for each digit class. We compare the predicted labels (y_pred) with the true labels (y_true) to obtain the metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
